package services

import (
	"context"
	"fmt"
	"sort"
	"strconv"
	"strings"
	"time"

	"github.com/easayliu/alist-aria2-download/internal/application/contracts"
	"github.com/easayliu/alist-aria2-download/internal/infrastructure/alist"
	"github.com/easayliu/alist-aria2-download/internal/infrastructure/config"
	"github.com/easayliu/alist-aria2-download/pkg/logger"
	"github.com/easayliu/alist-aria2-download/pkg/utils"
)

// AppFileService åº”ç”¨å±‚æ–‡ä»¶æœåŠ¡ - è´Ÿè´£æ–‡ä»¶ä¸šåŠ¡æµç¨‹ç¼–æ’
type AppFileService struct {
	config        *config.Config
	alistClient   *alist.Client
	downloadService contracts.DownloadService
}

// NewAppFileService åˆ›å»ºåº”ç”¨æ–‡ä»¶æœåŠ¡
func NewAppFileService(cfg *config.Config, downloadService contracts.DownloadService) contracts.FileService {
	return &AppFileService{
		config:        cfg,
		alistClient:   alist.NewClient(cfg.Alist.BaseURL, cfg.Alist.Username, cfg.Alist.Password),
		downloadService: downloadService,
	}
}

// SetDownloadService è®¾ç½®ä¸‹è½½æœåŠ¡ï¼ˆç”¨äºè§£å†³å¾ªç¯ä¾èµ–ï¼‰
func (s *AppFileService) SetDownloadService(downloadService contracts.DownloadService) {
	s.downloadService = downloadService
}

// ListFiles è·å–æ–‡ä»¶åˆ—è¡¨ - ç»Ÿä¸€çš„ä¸šåŠ¡é€»è¾‘
func (s *AppFileService) ListFiles(ctx context.Context, req contracts.FileListRequest) (*contracts.FileListResponse, error) {
	logger.Info("Listing files", "path", req.Path, "page", req.Page, "recursive", req.Recursive)

	// 1. å‚æ•°éªŒè¯å’Œé»˜è®¤å€¼è®¾ç½®
	if req.Page <= 0 {
		req.Page = 1
	}
	if req.PageSize <= 0 {
		req.PageSize = 50
	} else if req.PageSize > 1000 {
		req.PageSize = 1000
	}

	// 2. ç¡®ä¿AListå®¢æˆ·ç«¯å·²ç™»å½•å¹¶è·å–æ–‡ä»¶åˆ—è¡¨
	if s.alistClient.Token == "" {
		logger.Info("ğŸ”‘ ListFiles: æ£€æµ‹åˆ°æœªç™»å½•ï¼Œå¼€å§‹ç™»å½•AList", "baseURL", s.alistClient.BaseURL)
		if err := s.alistClient.Login(); err != nil {
			return nil, fmt.Errorf("failed to login to AList: %w", err)
		}
		logger.Info("âœ… ListFiles: AListç™»å½•æˆåŠŸ")
	}
	
	alistResp, err := s.alistClient.ListFiles(req.Path, req.Page, req.PageSize)
	if err != nil {
		return nil, fmt.Errorf("failed to list files: %w", err)
	}

	// 3. è½¬æ¢å¹¶åˆ†ç±»æ–‡ä»¶
	var files, directories []contracts.FileResponse
	summary := contracts.FileSummary{}

	for _, item := range alistResp.Data.Content {
		fileResp := s.convertToFileResponse(item, req.Path)

		if item.IsDir {
			directories = append(directories, fileResp)
			summary.TotalDirs++
			logger.Info("Added directory", "name", item.Name)
		} else {
			// åº”ç”¨è§†é¢‘è¿‡æ»¤
			if req.VideoOnly && !s.IsVideoFile(item.Name) {
				logger.Info("File filtered out by VideoOnly", "name", item.Name, "isVideo", s.IsVideoFile(item.Name))
				continue
			}

			files = append(files, fileResp)
			summary.TotalFiles++
			summary.TotalSize += item.Size
			logger.Info("Added file", "name", item.Name, "isVideo", s.IsVideoFile(item.Name))

			// åª’ä½“åˆ†ç±»ç»Ÿè®¡ - ä¼ å…¥å®Œæ•´è·¯å¾„ç”¨äºè·¯å¾„åˆ†ç±»
			s.updateMediaStats(&summary, fileResp.Path, item.Name)
		}
	}

	// 4. é€’å½’å¤„ç†å­ç›®å½•ï¼ˆå¦‚æœéœ€è¦ï¼‰
	if req.Recursive {
		for _, dir := range directories {
			subReq := req
			subReq.Path = dir.Path
			subReq.Recursive = false // é¿å…æ— é™é€’å½’
			
			subResp, err := s.ListFiles(ctx, subReq)
			if err != nil {
				logger.Warn("Failed to list subdirectory", "path", dir.Path, "error", err)
				continue
			}
			
			files = append(files, subResp.Files...)
			summary.TotalFiles += subResp.Summary.TotalFiles
			summary.TotalSize += subResp.Summary.TotalSize
			summary.VideoFiles += subResp.Summary.VideoFiles
			summary.MovieFiles += subResp.Summary.MovieFiles
			summary.TVFiles += subResp.Summary.TVFiles
			summary.OtherFiles += subResp.Summary.OtherFiles
		}
	}

	// 5. åº”ç”¨æ’åº
	s.sortFiles(files, req.SortBy, req.SortOrder)

	// 6. åº”ç”¨åˆ†é¡µï¼ˆå¯¹äºé€’å½’ç»“æœï¼‰
	if req.Recursive {
		start := (req.Page - 1) * req.PageSize
		end := start + req.PageSize
		if start >= len(files) {
			files = []contracts.FileResponse{}
		} else if end > len(files) {
			files = files[start:]
		} else {
			files = files[start:end]
		}
	}

	// 7. æ„å»ºå“åº”
	summary.TotalSizeFormatted = s.FormatFileSize(summary.TotalSize)
	parentPath := s.getParentPath(req.Path)

	return &contracts.FileListResponse{
		Files:       files,
		Directories: directories,
		CurrentPath: req.Path,
		ParentPath:  parentPath,
		TotalCount:  summary.TotalFiles,
		Summary:     summary,
		Pagination: contracts.Pagination{
			Page:     req.Page,
			PageSize: req.PageSize,
			Total:    summary.TotalFiles,
			HasNext:  req.Page*req.PageSize < summary.TotalFiles,
			HasPrev:  req.Page > 1,
		},
	}, nil
}

// GetFileInfo è·å–æ–‡ä»¶è¯¦ç»†ä¿¡æ¯
func (s *AppFileService) GetFileInfo(ctx context.Context, path string) (*contracts.FileResponse, error) {
	// ä»è·¯å¾„ä¸­æå–ç›®å½•å’Œæ–‡ä»¶å
	parentDir := utils.GetParentPath(path)
	fileName := utils.GetFileName(path)

	// è·å–çˆ¶ç›®å½•åˆ—è¡¨
	listResp, err := s.alistClient.ListFiles(parentDir, 1, 1000)
	if err != nil {
		return nil, fmt.Errorf("failed to get file info: %w", err)
	}

	// æŸ¥æ‰¾ç›®æ ‡æ–‡ä»¶
	for _, item := range listResp.Data.Content {
		if item.Name == fileName {
			fileResp := s.convertToFileResponse(item, parentDir)
			
			// å¦‚æœä¸æ˜¯ç›®å½•ï¼Œè·å–å®é™…çš„raw_urlç”¨äºä¸‹è½½
			if !item.IsDir {
				logger.Info("ğŸ”½ GetFileInfo: å‡†å¤‡è·å–æ–‡ä»¶çš„çœŸå®ä¸‹è½½URL", "file", fileName, "path", path)
				internalURL, externalURL := s.getRealDownloadURLs(path)
				fileResp.InternalURL = internalURL
				fileResp.ExternalURL = externalURL
				logger.Info("ğŸ”½ GetFileInfo: å·²æ›´æ–°æ–‡ä»¶å“åº”çš„URL", "internal", internalURL, "external", externalURL)
			}
			
			return &fileResp, nil
		}
	}

	return nil, fmt.Errorf("file not found: %s", path)
}

// SearchFiles æœç´¢æ–‡ä»¶
func (s *AppFileService) SearchFiles(ctx context.Context, req contracts.FileSearchRequest) (*contracts.FileListResponse, error) {
	// ç®€å•å®ç°ï¼šåœ¨æŒ‡å®šè·¯å¾„ä¸‹é€’å½’æœç´¢
	searchPath := req.Path
	if searchPath == "" {
		searchPath = s.config.Alist.DefaultPath
		if searchPath == "" {
			searchPath = "/"
		}
	}

	listReq := contracts.FileListRequest{
		Path:      searchPath,
		Recursive: true,
		PageSize:  req.Limit,
	}

	listResp, err := s.ListFiles(ctx, listReq)
	if err != nil {
		return nil, fmt.Errorf("failed to search files: %w", err)
	}

	// åº”ç”¨æœç´¢è¿‡æ»¤
	var filteredFiles []contracts.FileResponse
	query := strings.ToLower(req.Query)

	for _, file := range listResp.Files {
		// æ–‡ä»¶ååŒ¹é…
		if !strings.Contains(strings.ToLower(file.Name), query) {
			continue
		}

		// æ–‡ä»¶ç±»å‹è¿‡æ»¤
		if req.FileType != "" && s.GetFileCategory(file.Name) != req.FileType {
			continue
		}

		// æ–‡ä»¶å¤§å°è¿‡æ»¤
		if req.MinSize > 0 && file.Size < req.MinSize {
			continue
		}
		if req.MaxSize > 0 && file.Size > req.MaxSize {
			continue
		}

		// ä¿®æ”¹æ—¶é—´è¿‡æ»¤
		if req.ModifiedAfter != nil && file.Modified.Before(*req.ModifiedAfter) {
			continue
		}
		if req.ModifiedBefore != nil && file.Modified.After(*req.ModifiedBefore) {
			continue
		}

		filteredFiles = append(filteredFiles, file)
	}

	listResp.Files = filteredFiles
	listResp.TotalCount = len(filteredFiles)
	return listResp, nil
}

// GetFilesByTimeRange æ ¹æ®æ—¶é—´èŒƒå›´è·å–æ–‡ä»¶
func (s *AppFileService) GetFilesByTimeRange(ctx context.Context, req contracts.TimeRangeFileRequest) (*contracts.TimeRangeFileResponse, error) {
	logger.Info("GetFilesByTimeRange called", 
		"path", req.Path,
		"startTime", req.StartTime.Format("2006-01-02 15:04:05 -07:00"), 
		"endTime", req.EndTime.Format("2006-01-02 15:04:05 -07:00"),
		"startUnix", req.StartTime.Unix(),
		"endUnix", req.EndTime.Unix(),
		"videoOnly", req.VideoOnly)

	// ä½¿ç”¨è‡ªå®šä¹‰é€’å½’é€»è¾‘ï¼Œå…ˆæ£€æŸ¥ç›®å½•æ—¶é—´å†å†³å®šæ˜¯å¦é€’å½’
	var filteredFiles []contracts.FileResponse
	err := s.collectFilesInTimeRange(ctx, req.Path, req.StartTime, req.EndTime, req.VideoOnly, &filteredFiles)
	if err != nil {
		return nil, fmt.Errorf("failed to collect files: %w", err)
	}

	logger.Info("Time range filtering completed", "filteredCount", len(filteredFiles))

	// é‡æ–°è®¡ç®—æ‘˜è¦
	summary := s.calculateFileSummary(filteredFiles)

	return &contracts.TimeRangeFileResponse{
		Files: filteredFiles,
		TimeRange: contracts.TimeRange{
			Start: req.StartTime,
			End:   req.EndTime,
		},
		Summary: summary,
	}, nil
}

// collectFilesInTimeRange é€’å½’æ”¶é›†åœ¨æ—¶é—´èŒƒå›´å†…çš„æ–‡ä»¶
func (s *AppFileService) collectFilesInTimeRange(ctx context.Context, path string, startTime, endTime time.Time, videoOnly bool, result *[]contracts.FileResponse) error {
	logger.Info("Collecting files in path", "path", path)

	// è·å–å½“å‰ç›®å½•çš„æ–‡ä»¶åˆ—è¡¨ï¼ˆéé€’å½’ï¼‰
	alistResp, err := s.alistClient.ListFiles(path, 1, 1000)
	if err != nil {
		return fmt.Errorf("failed to list files in %s: %w", path, err)
	}

	for _, item := range alistResp.Data.Content {
		fileResp := s.convertToFileResponse(item, path)
		
		// æ£€æŸ¥æ—¶é—´èŒƒå›´
		inTimeRange := utils.IsInRange(fileResp.Modified, startTime, endTime)
		
		logger.Info("Checking item", 
			"name", item.Name, 
			"isDir", item.IsDir,
			"modified", fileResp.Modified.Format("2006-01-02 15:04:05 -07:00"),
			"modifiedUnix", fileResp.Modified.Unix(),
			"inTimeRange", inTimeRange)

		if item.IsDir {
			// å¯¹äºç›®å½•ï¼Œå¦‚æœç›®å½•ä¿®æ”¹æ—¶é—´åœ¨èŒƒå›´å†…ï¼Œåˆ™é€’å½’æœç´¢
			if inTimeRange {
				logger.Info("Directory in time range, recursing", "dir", item.Name)
				subPath := utils.JoinPath(path, item.Name)
				err := s.collectFilesInTimeRange(ctx, subPath, startTime, endTime, videoOnly, result)
				if err != nil {
					logger.Warn("Failed to recurse into directory", "dir", item.Name, "error", err)
					// ç»§ç»­å¤„ç†å…¶ä»–ç›®å½•ï¼Œä¸å› å•ä¸ªç›®å½•å¤±è´¥è€Œåœæ­¢
				}
			} else {
				logger.Info("Directory not in time range, skipping", "dir", item.Name)
			}
		} else {
			// å¯¹äºæ–‡ä»¶ï¼Œæ£€æŸ¥æ—¶é—´èŒƒå›´å’Œè§†é¢‘è¿‡æ»¤
			if inTimeRange {
				if !videoOnly || s.IsVideoFile(item.Name) {
					logger.Info("File matches criteria, adding", "file", item.Name, "isVideo", s.IsVideoFile(item.Name))
					
					// ä¸ºç¬¦åˆæ¡ä»¶çš„æ–‡ä»¶è·å–çœŸå®çš„ä¸‹è½½URL
					filePath := utils.JoinPath(path, item.Name)
					internalURL, externalURL := s.getRealDownloadURLs(filePath)
					fileResp.InternalURL = internalURL
					fileResp.ExternalURL = externalURL
					logger.Info("ğŸ¯ å·²ä¸ºæ—¶é—´èŒƒå›´æ–‡ä»¶è·å–çœŸå®ä¸‹è½½URL", "file", item.Name, "url", internalURL)
					
					*result = append(*result, fileResp)
				} else {
					logger.Info("File not video, skipping", "file", item.Name)
				}
			} else {
				logger.Info("File not in time range, skipping", "file", item.Name)
			}
		}
	}

	return nil
}

// GetRecentFiles è·å–æœ€è¿‘æ–‡ä»¶
func (s *AppFileService) GetRecentFiles(ctx context.Context, req contracts.RecentFilesRequest) (*contracts.FileListResponse, error) {
	// ä½¿ç”¨æ—¶é—´å·¥å…·åˆ›å»ºæ—¶é—´èŒƒå›´
	timeRange := utils.CreateTimeRangeFromHours(req.HoursAgo)

	timeRangeReq := contracts.TimeRangeFileRequest{
		Path:      req.Path,
		StartTime: timeRange.Start,
		EndTime:   timeRange.End,
		VideoOnly: req.VideoOnly,
	}

	timeRangeResp, err := s.GetFilesByTimeRange(ctx, timeRangeReq)
	if err != nil {
		return nil, err
	}

	// è½¬æ¢ä¸ºåˆ—è¡¨å“åº”æ ¼å¼
	files := timeRangeResp.Files
	if req.Limit > 0 && len(files) > req.Limit {
		files = files[:req.Limit]
	}

	return &contracts.FileListResponse{
		Files:       files,
		CurrentPath: req.Path,
		TotalCount:  len(files),
		Summary:     timeRangeResp.Summary,
	}, nil
}

// GetYesterdayFiles è·å–æ˜¨å¤©çš„æ–‡ä»¶
func (s *AppFileService) GetYesterdayFiles(ctx context.Context, path string) (*contracts.FileListResponse, error) {
	// ä½¿ç”¨æ—¶é—´å·¥å…·åˆ›å»ºæ˜¨å¤©çš„æ—¶é—´èŒƒå›´
	yesterdayRange := utils.CreateYesterdayRange()

	timeRangeReq := contracts.TimeRangeFileRequest{
		Path:      path,
		StartTime: yesterdayRange.Start,
		EndTime:   yesterdayRange.End,
		VideoOnly: true,
	}

	timeRangeResp, err := s.GetFilesByTimeRange(ctx, timeRangeReq)
	if err != nil {
		return nil, err
	}

	return &contracts.FileListResponse{
		Files:       timeRangeResp.Files,
		CurrentPath: path,
		TotalCount:  len(timeRangeResp.Files),
		Summary:     timeRangeResp.Summary,
	}, nil
}

// ClassifyFiles æ–‡ä»¶åˆ†ç±»
func (s *AppFileService) ClassifyFiles(ctx context.Context, req contracts.FileClassificationRequest) (*contracts.FileClassificationResponse, error) {
	classified := make(map[string][]contracts.FileResponse)
	summary := contracts.ClassificationSummary{
		Categories: make(map[string]int),
	}

	for _, file := range req.Files {
		category := s.GetFileCategory(file.Name)
		classified[category] = append(classified[category], file)
		summary.Categories[category]++

		// ç‰¹æ®Šåˆ†ç±»ç»Ÿè®¡
		switch category {
		case "movie":
			summary.MovieCount++
		case "tv":
			summary.TVCount++
		default:
			summary.OtherCount++
		}
	}

	return &contracts.FileClassificationResponse{
		ClassifiedFiles: classified,
		Summary:         summary,
	}, nil
}

// GetFilesByCategory æ ¹æ®åˆ†ç±»è·å–æ–‡ä»¶
func (s *AppFileService) GetFilesByCategory(ctx context.Context, path string, category string) (*contracts.FileListResponse, error) {
	listReq := contracts.FileListRequest{
		Path:      path,
		Recursive: true,
		PageSize:  10000,
	}

	listResp, err := s.ListFiles(ctx, listReq)
	if err != nil {
		return nil, err
	}

	// æŒ‰åˆ†ç±»è¿‡æ»¤
	var filteredFiles []contracts.FileResponse
	for _, file := range listResp.Files {
		if s.GetFileCategory(file.Name) == category {
			filteredFiles = append(filteredFiles, file)
		}
	}

	listResp.Files = filteredFiles
	listResp.TotalCount = len(filteredFiles)
	listResp.Summary = s.calculateFileSummary(filteredFiles)

	return listResp, nil
}

// DownloadFile ä¸‹è½½å•ä¸ªæ–‡ä»¶
func (s *AppFileService) DownloadFile(ctx context.Context, req contracts.FileDownloadRequest) (*contracts.DownloadResponse, error) {
	logger.Info("ğŸ“ å¼€å§‹ä¸‹è½½å•ä¸ªæ–‡ä»¶", "filePath", req.FilePath)
	
	// æ£€æŸ¥ä¸‹è½½æœåŠ¡æ˜¯å¦å¯ç”¨
	if s.downloadService == nil {
		return nil, fmt.Errorf("download service not available")
	}
	
	// è·å–æ–‡ä»¶ä¿¡æ¯
	fileInfo, err := s.GetFileInfo(ctx, req.FilePath)
	if err != nil {
		logger.Error("âŒ è·å–æ–‡ä»¶ä¿¡æ¯å¤±è´¥", "filePath", req.FilePath, "error", err)
		return nil, fmt.Errorf("failed to get file info: %w", err)
	}

	logger.Info("ğŸ“‹ æ–‡ä»¶ä¿¡æ¯è·å–æˆåŠŸ", 
		"fileName", fileInfo.Name,
		"fileSize", fileInfo.Size,
		"downloadURL", fileInfo.InternalURL)

	// æ„å»ºä¸‹è½½è¯·æ±‚
	downloadReq := contracts.DownloadRequest{
		URL:          fileInfo.InternalURL,
		Filename:     fileInfo.Name,
		Directory:    req.TargetDir,
		Options:      req.Options,
		AutoClassify: req.AutoClassify,
	}

	if downloadReq.Directory == "" {
		downloadReq.Directory = s.GenerateDownloadPath(*fileInfo)
	}

	logger.Info("ğŸš€ å‡†å¤‡åˆ›å»ºä¸‹è½½ä»»åŠ¡", 
		"url", downloadReq.URL,
		"filename", downloadReq.Filename,
		"directory", downloadReq.Directory)

	return s.downloadService.CreateDownload(ctx, downloadReq)
}

// DownloadFiles æ‰¹é‡ä¸‹è½½æ–‡ä»¶
func (s *AppFileService) DownloadFiles(ctx context.Context, req contracts.BatchFileDownloadRequest) (*contracts.BatchDownloadResponse, error) {
	// æ£€æŸ¥ä¸‹è½½æœåŠ¡æ˜¯å¦å¯ç”¨
	if s.downloadService == nil {
		return nil, fmt.Errorf("download service not available")
	}
	
	var downloadRequests []contracts.DownloadRequest

	for _, fileReq := range req.Files {
		fileInfo, err := s.GetFileInfo(ctx, fileReq.FilePath)
		if err != nil {
			logger.Warn("Failed to get file info", "path", fileReq.FilePath, "error", err)
			continue
		}

		downloadReq := contracts.DownloadRequest{
			URL:          fileInfo.InternalURL,
			Filename:     fileInfo.Name,
			Directory:    fileReq.TargetDir,
			Options:      fileReq.Options,
			AutoClassify: fileReq.AutoClassify,
		}

		// åº”ç”¨å…¨å±€è®¾ç½®
		if req.TargetDir != "" && downloadReq.Directory == "" {
			downloadReq.Directory = req.TargetDir
		}
		if req.AutoClassify {
			downloadReq.AutoClassify = true
		}

		if downloadReq.Directory == "" {
			downloadReq.Directory = s.GenerateDownloadPath(*fileInfo)
		}

		downloadRequests = append(downloadRequests, downloadReq)
	}

	batchReq := contracts.BatchDownloadRequest{
		Items:        downloadRequests,
		Directory:    req.TargetDir,
		VideoOnly:    req.VideoOnly,
		AutoClassify: req.AutoClassify,
	}

	return s.downloadService.CreateBatchDownload(ctx, batchReq)
}

// DownloadDirectory ä¸‹è½½ç›®å½•
func (s *AppFileService) DownloadDirectory(ctx context.Context, req contracts.DirectoryDownloadRequest) (*contracts.BatchDownloadResponse, error) {
	// æ£€æŸ¥ä¸‹è½½æœåŠ¡æ˜¯å¦å¯ç”¨
	if s.downloadService == nil {
		return nil, fmt.Errorf("download service not available")
	}
	
	// è·å–ç›®å½•ä¸‹çš„æ‰€æœ‰æ–‡ä»¶
	listReq := contracts.FileListRequest{
		Path:      req.DirectoryPath,
		Recursive: req.Recursive,
		VideoOnly: req.VideoOnly,
		PageSize:  10000,
	}

	listResp, err := s.ListFiles(ctx, listReq)
	if err != nil {
		return nil, fmt.Errorf("failed to list directory: %w", err)
	}

	// è½¬æ¢ä¸ºä¸‹è½½è¯·æ±‚
	var downloadRequests []contracts.DownloadRequest
	for _, file := range listResp.Files {
		// åŠ¨æ€è·å–çœŸå®çš„ä¸‹è½½URL
		logger.Info("ğŸ“‚ è·å–ç›®å½•ä¸­æ–‡ä»¶çš„ä¸‹è½½URL", "file", file.Name, "path", file.Path)
		internalURL, _ := s.getRealDownloadURLs(file.Path)
		
		downloadReq := contracts.DownloadRequest{
			URL:          internalURL,
			Filename:     file.Name,
			Directory:    req.TargetDir,
			AutoClassify: req.AutoClassify,
		}

		if downloadReq.Directory == "" {
			downloadReq.Directory = s.GenerateDownloadPath(file)
		}

		downloadRequests = append(downloadRequests, downloadReq)
	}

	batchReq := contracts.BatchDownloadRequest{
		Items:        downloadRequests,
		Directory:    req.TargetDir,
		VideoOnly:    req.VideoOnly,
		AutoClassify: req.AutoClassify,
	}

	return s.downloadService.CreateBatchDownload(ctx, batchReq)
}

// IsVideoFile æ£€æŸ¥æ˜¯å¦ä¸ºè§†é¢‘æ–‡ä»¶
func (s *AppFileService) IsVideoFile(filename string) bool {
	if filename == "" {
		return false
	}

	ext := strings.ToLower(filename)
	if idx := strings.LastIndex(ext, "."); idx != -1 {
		ext = ext[idx+1:]
	}

	for _, videoExt := range s.config.Download.VideoExts {
		if ext == strings.ToLower(videoExt) {
			return true
		}
	}

	return false
}

// GetFileCategory è·å–æ–‡ä»¶åˆ†ç±»
func (s *AppFileService) GetFileCategory(filename string) string {
	if !s.IsVideoFile(filename) {
		return "other"
	}

	filename = strings.ToLower(filename)

	// ç”µå½±å…³é”®è¯
	movieKeywords := []string{"movie", "film", "ç”µå½±", "è“å…‰", "bluray", "bd", "4k", "1080p", "720p"}
	for _, keyword := range movieKeywords {
		if strings.Contains(filename, keyword) {
			return "movie"
		}
	}

	// ç”µè§†å‰§å…³é”®è¯
	tvKeywords := []string{"tv", "series", "episode", "ep", "s01", "s02", "s03", "season", "ç”µè§†å‰§", "è¿ç»­å‰§"}
	for _, keyword := range tvKeywords {
		if strings.Contains(filename, keyword) {
			return "tv"
		}
	}

	// ç»¼è‰ºå…³é”®è¯
	varietyKeywords := []string{"variety", "show", "ç»¼è‰º", "å¨±ä¹"}
	for _, keyword := range varietyKeywords {
		if strings.Contains(filename, keyword) {
			return "variety"
		}
	}

	return "video"
}

// GetMediaType è·å–åª’ä½“ç±»å‹ï¼ˆç”¨äºç»Ÿè®¡ï¼‰
func (s *AppFileService) GetMediaType(filePath string) string {
	// é¦–å…ˆæ£€æŸ¥è·¯å¾„ä¸­çš„ç±»å‹æŒ‡ç¤ºå™¨ï¼ˆä¼˜å…ˆçº§ï¼‰
	pathCategory := s.GetCategoryFromPath(filePath)
	if pathCategory != "" {
		switch pathCategory {
		case "movie":
			return "movie"
		case "tv":
			return "tv"
		case "variety":
			return "tv" // ç»¼è‰ºèŠ‚ç›®ä¹Ÿç®—ä½œTVç±»å‹
		default:
			return "other"
		}
	}

	// å›é€€åˆ°åŸºäºæ–‡ä»¶åçš„åˆ†ç±»
	filename := utils.GetFileName(filePath)
	category := s.GetFileCategory(filename)
	switch category {
	case "movie":
		return "movie"
	case "tv":
		return "tv"
	case "variety":
		return "tv" // ç»¼è‰ºèŠ‚ç›®ä¹Ÿç®—ä½œTVç±»å‹
	default:
		return "other"
	}
}

// FormatFileSize æ ¼å¼åŒ–æ–‡ä»¶å¤§å°
func (s *AppFileService) FormatFileSize(size int64) string {
	return utils.FormatFileSize(size)
}

// GenerateDownloadPath ç”Ÿæˆä¸‹è½½è·¯å¾„
func (s *AppFileService) GenerateDownloadPath(file contracts.FileResponse) string {
	baseDir := s.config.Aria2.DownloadDir
	if baseDir == "" {
		baseDir = "/downloads"
	}

	// é¦–å…ˆæ£€æŸ¥è·¯å¾„ä¸­çš„ç±»å‹æŒ‡ç¤ºå™¨ï¼ˆä¼˜å…ˆçº§æœ€é«˜ï¼‰
	pathCategory := s.GetCategoryFromPath(file.Path)
	logger.Info("ğŸ·ï¸  è·¯å¾„åˆ†ç±»åˆ†æ", "path", file.Path, "pathCategory", pathCategory)
	
	if pathCategory != "" {
		// å¯¹äºç”µè§†å‰§ï¼Œä½¿ç”¨æ™ºèƒ½è·¯å¾„è§£æå’Œé‡ç»„
		if pathCategory == "tv" {
			smartPath := s.generateSmartTVPath(file.Path, baseDir)
			if smartPath != "" {
				logger.Info("ğŸ¯ ä½¿ç”¨æ™ºèƒ½ç”µè§†å‰§è·¯å¾„", "file", file.Name, "path", file.Path, "smartPath", smartPath)
				return smartPath
			}
		}
		
		// æå–å¹¶ä¿ç•™åŸå§‹è·¯å¾„ç»“æ„
		targetDir := s.extractPathStructure(file.Path, pathCategory, baseDir)
		if targetDir != "" {
			logger.Info("âœ… ä½¿ç”¨è·¯å¾„åˆ†ç±»ç»“æœï¼ˆä¿ç•™ç›®å½•ç»“æ„ï¼‰", "file", file.Name, "path", file.Path, "pathCategory", pathCategory, "targetDir", targetDir)
			return targetDir
		}
	}

	// å¦‚æœè·¯å¾„åˆ†ç±»å¤±è´¥ï¼Œç›´æ¥ä½¿ç”¨é»˜è®¤ç›®å½•
	defaultDir := utils.JoinPath(baseDir, "others")
	logger.Info("âš ï¸  è·¯å¾„åˆ†ç±»å¤±è´¥ï¼Œä½¿ç”¨é»˜è®¤ç›®å½•", "file", file.Name, "path", file.Path, "defaultDir", defaultDir)
	return defaultDir
}

// extractPathStructure ä»åŸå§‹è·¯å¾„ä¸­æå–å¹¶ä¿ç•™ç›®å½•ç»“æ„ï¼ˆè¿‡æ»¤å…¶ä»–åˆ†ç±»å…³é”®è¯ï¼‰
func (s *AppFileService) extractPathStructure(filePath, pathCategory, baseDir string) string {
	// å°†è·¯å¾„è½¬ä¸ºå°å†™ç”¨äºåŒ¹é…
	pathLower := strings.ToLower(filePath)
	
	// å®šä¹‰æ‰€æœ‰åˆ†ç±»å…³é”®è¯
	allCategoryKeywords := []string{"tvs", "movies", "variety", "show", "ç»¼è‰º", "å¨±ä¹", "videos", "video", "è§†é¢‘"}
	
	// æ ¹æ®åˆ†ç±»æ‰¾åˆ°å¯¹åº”çš„å…³é”®è¯å’Œç›®æ ‡ç›®å½•
	var keywordFound string
	var targetCategoryDir string
	
	switch pathCategory {
	case "tv":
		targetCategoryDir = "tvs"
		keywordFound = "tvs"
	case "movie":
		targetCategoryDir = "movies"
		keywordFound = "movies"
	case "variety":
		targetCategoryDir = "variety"
		// å¯¹äº varietyï¼Œé€‰æ‹©ç¬¬ä¸€ä¸ªåŒ¹é…çš„å…³é”®è¯
		varietyKeywords := []string{"variety", "show", "ç»¼è‰º", "å¨±ä¹"}
		for _, keyword := range varietyKeywords {
			if strings.Contains(pathLower, keyword) {
				keywordFound = keyword
				break
			}
		}
	case "video":
		targetCategoryDir = "videos"
		// å¯¹äº videoï¼Œé€‰æ‹©ç¬¬ä¸€ä¸ªåŒ¹é…çš„å…³é”®è¯
		videoKeywords := []string{"videos", "video", "è§†é¢‘"}
		for _, keyword := range videoKeywords {
			if strings.Contains(pathLower, keyword) {
				keywordFound = keyword
				break
			}
		}
	}
	
	if keywordFound == "" {
		logger.Warn("æœªæ‰¾åˆ°åŒ¹é…çš„å…³é”®è¯", "filePath", filePath, "pathCategory", pathCategory)
		return ""
	}
	
	// åœ¨åŸå§‹è·¯å¾„ä¸­æ‰¾åˆ°å…³é”®è¯çš„ä½ç½®ï¼ˆä¿æŒåŸå§‹å¤§å°å†™ï¼‰
	keywordIndex := strings.Index(pathLower, keywordFound)
	if keywordIndex == -1 {
		logger.Warn("æ— æ³•åœ¨åŸå§‹è·¯å¾„ä¸­æ‰¾åˆ°å…³é”®è¯ä½ç½®", "filePath", filePath, "keywordFound", keywordFound)
		return ""
	}
	
	// æå–å…³é”®è¯ä¹‹åçš„è·¯å¾„éƒ¨åˆ†
	afterKeywordStart := keywordIndex + len(keywordFound)
	if afterKeywordStart < len(filePath) && filePath[afterKeywordStart] == '/' {
		afterKeywordStart++ // è·³è¿‡å…³é”®è¯åçš„ /
	}
	
	afterKeyword := ""
	if afterKeywordStart < len(filePath) {
		afterKeyword = filePath[afterKeywordStart:]
	}
	
	logger.Info("ğŸ” æå–è·¯å¾„ç‰‡æ®µ", "keywordFound", keywordFound, "afterKeyword", afterKeyword)
	
	// è·å–æ–‡ä»¶çš„çˆ¶ç›®å½•ï¼ˆå»æ‰æ–‡ä»¶åï¼‰
	parentDir := utils.GetParentPath(afterKeyword)
	
	// å…³é”®æ­¥éª¤ï¼šè¿‡æ»¤æ‰è·¯å¾„ä¸­çš„å…¶ä»–åˆ†ç±»å…³é”®è¯
	if parentDir != "" && parentDir != "/" {
		parentDir = s.filterCategoryKeywords(parentDir, allCategoryKeywords)
		logger.Info("ğŸ§¹ è¿‡æ»¤åˆ†ç±»å…³é”®è¯å", "originalParentDir", utils.GetParentPath(afterKeyword), "filteredParentDir", parentDir)
	}
	
	// æ„å»ºæœ€ç»ˆè·¯å¾„ï¼šbaseDir + åˆ†ç±»ç›®å½• + è¿‡æ»¤åçš„ç›®å½•ç»“æ„
	if parentDir == "" || parentDir == "/" {
		// å¦‚æœæ²¡æœ‰å­ç›®å½•ï¼Œç›´æ¥ä½¿ç”¨åˆ†ç±»ç›®å½•
		targetDir := utils.JoinPath(baseDir, targetCategoryDir)
		logger.Info("ğŸ“ æ— å­ç›®å½•ï¼Œä½¿ç”¨åˆ†ç±»æ ¹ç›®å½•", "targetDir", targetDir)
		return targetDir
	} else {
		// ä¿ç•™è¿‡æ»¤åçš„å­ç›®å½•ç»“æ„
		targetDir := utils.JoinPath(baseDir, targetCategoryDir, parentDir)
		logger.Info("âœ… æœ€ç»ˆä¸‹è½½è·¯å¾„", "targetDir", targetDir)
		return targetDir
	}
}

// filterCategoryKeywords è¿‡æ»¤è·¯å¾„ä¸­çš„åˆ†ç±»å…³é”®è¯ç›®å½•
func (s *AppFileService) filterCategoryKeywords(path string, keywords []string) string {
	if path == "" || path == "/" {
		return path
	}
	
	logger.Info("ğŸ§¹ å¼€å§‹è¿‡æ»¤åˆ†ç±»å…³é”®è¯", "originalPath", path, "keywords", keywords)
	
	// åˆ†å‰²è·¯å¾„ä¸ºç›®å½•ç‰‡æ®µ
	parts := strings.Split(strings.Trim(path, "/"), "/")
	var filteredParts []string
	
	for _, part := range parts {
		if part == "" {
			continue
		}
		
		partLower := strings.ToLower(part)
		isKeyword := false
		
		// æ£€æŸ¥æ˜¯å¦æ˜¯å®Œå…¨åŒ¹é…çš„åˆ†ç±»å…³é”®è¯
		for _, keyword := range keywords {
			if partLower == keyword {
				logger.Info("ğŸš« è¿‡æ»¤æ‰åˆ†ç±»å…³é”®è¯ç›®å½•ï¼ˆå®Œå…¨åŒ¹é…ï¼‰", "part", part, "keyword", keyword)
				isKeyword = true
				break
			}
		}
		
		// å¦‚æœä¸æ˜¯å…³é”®è¯ï¼Œä¿ç•™è¿™ä¸ªç›®å½•
		if !isKeyword {
			logger.Info("âœ… ä¿ç•™ç›®å½•", "part", part)
			filteredParts = append(filteredParts, part)
		}
	}
	
	// é‡æ–°ç»„è£…è·¯å¾„
	if len(filteredParts) == 0 {
		logger.Info("âš ï¸  æ‰€æœ‰ç›®å½•éƒ½è¢«è¿‡æ»¤ï¼Œè¿”å›ç©ºè·¯å¾„")
		return ""
	}
	
	result := strings.Join(filteredParts, "/")
	logger.Info("ğŸ”§ è·¯å¾„è¿‡æ»¤ç»“æœ", "original", path, "filtered", result, "removedParts", len(parts)-len(filteredParts))
	return result
}

// GetStorageInfo è·å–å­˜å‚¨ä¿¡æ¯
func (s *AppFileService) GetStorageInfo(ctx context.Context, path string) (map[string]interface{}, error) {
	// è·å–ç›®å½•ç»Ÿè®¡ä¿¡æ¯
	listReq := contracts.FileListRequest{
		Path:      path,
		Recursive: true,
		PageSize:  10000,
	}

	listResp, err := s.ListFiles(ctx, listReq)
	if err != nil {
		return nil, fmt.Errorf("failed to get storage info: %w", err)
	}

	return map[string]interface{}{
		"path":              path,
		"total_files":       listResp.Summary.TotalFiles,
		"total_directories": listResp.Summary.TotalDirs,
		"total_size":        listResp.Summary.TotalSize,
		"total_size_formatted": listResp.Summary.TotalSizeFormatted,
		"video_files":       listResp.Summary.VideoFiles,
		"movie_files":       listResp.Summary.MovieFiles,
		"tv_files":          listResp.Summary.TVFiles,
		"other_files":       listResp.Summary.OtherFiles,
	}, nil
}

// ========== ç§æœ‰æ–¹æ³• ==========

// convertToFileResponse è½¬æ¢AListæ–‡ä»¶å¯¹è±¡åˆ°å“åº”æ ¼å¼
func (s *AppFileService) convertToFileResponse(item alist.FileItem, basePath string) contracts.FileResponse {
	fullPath := utils.JoinPath(basePath, item.Name)
	
	// è§£æä¿®æ”¹æ—¶é—´
	logger.Info("Parsing time", "file", item.Name, "modifiedString", item.Modified)
	
	modifiedTime, err := utils.ParseTime(item.Modified)
	if err != nil {
		logger.Warn("Failed to parse time, using zero time", "file", item.Name, "modifiedString", item.Modified, "error", err)
		modifiedTime = time.Time{} // é›¶å€¼æ—¶é—´
	} else {
		logger.Info("Time parsed successfully", "file", item.Name, "parsedTime", modifiedTime.Format("2006-01-02 15:04:05 -07:00"), "unix", modifiedTime.Unix(), "location", modifiedTime.Location().String())
	}
	
	resp := contracts.FileResponse{
		Name:          item.Name,
		Path:          fullPath,
		Size:          item.Size,
		SizeFormatted: s.FormatFileSize(item.Size),
		Modified:      modifiedTime,
		IsDir:         item.IsDir,
	}

	if !item.IsDir {
		// ä¼˜å…ˆä½¿ç”¨è·¯å¾„åˆ†ç±»ï¼Œå›é€€åˆ°æ–‡ä»¶ååˆ†ç±»
		pathCategory := s.GetCategoryFromPath(fullPath)
		if pathCategory != "" {
			resp.MediaType = pathCategory
			resp.Category = pathCategory
			logger.Info("ğŸ“ convertToFileResponse: ä½¿ç”¨è·¯å¾„åˆ†ç±»", "file", item.Name, "path", fullPath, "category", pathCategory)
		} else {
			// å›é€€åˆ°æ–‡ä»¶ååˆ†ç±»ï¼ˆå¦‚æœè·¯å¾„åˆ†ç±»å¤±è´¥ï¼‰
			fileCategory := s.GetFileCategory(item.Name)
			resp.MediaType = fileCategory
			resp.Category = fileCategory
			logger.Info("ğŸ“ convertToFileResponse: ä½¿ç”¨æ–‡ä»¶ååˆ†ç±»", "file", item.Name, "category", fileCategory)
		}
		
		resp.DownloadPath = s.GenerateDownloadPath(resp)
		
		// ç›´æ¥è·å–çœŸå®çš„raw_urlç”¨äºä¸‹è½½ï¼ˆé‡‡ç”¨å»¶è¿ŸåŠ è½½æ–¹å¼é¿å…æ€§èƒ½é—®é¢˜ï¼‰
		// URLå°†åœ¨å®é™…éœ€è¦æ—¶é€šè¿‡getRealDownloadURLsæ–¹æ³•è·å–
		resp.InternalURL = ""  // å°†åœ¨éœ€è¦æ—¶å¡«å……
		resp.ExternalURL = ""  // å°†åœ¨éœ€è¦æ—¶å¡«å……
	}

	return resp
}

// getRealDownloadURLs è·å–å®é™…çš„ä¸‹è½½URLï¼ˆå‚è€ƒæ—§å®ç°çš„ç®€å•æœ‰æ•ˆæ–¹æ³•ï¼‰
func (s *AppFileService) getRealDownloadURLs(filePath string) (internalURL, externalURL string) {
	logger.Info("ğŸ” å¼€å§‹è·å–æ–‡ä»¶çš„raw_url", "path", filePath)
	
	// ç¡®ä¿AListå®¢æˆ·ç«¯å·²ç™»å½•
	if s.alistClient.Token == "" {
		logger.Info("ğŸ”‘ æ£€æµ‹åˆ°æœªç™»å½•ï¼Œå¼€å§‹ç™»å½•AList", "baseURL", s.alistClient.BaseURL)
		if err := s.alistClient.Login(); err != nil {
			logger.Error("âŒ AListç™»å½•å¤±è´¥", "error", err)
			fallbackInternal := s.generateInternalURL(filePath)
			fallbackExternal := s.generateExternalURL(filePath)
			logger.Info("ğŸ”„ ç™»å½•å¤±è´¥ï¼Œä½¿ç”¨å›é€€URL", "internal", fallbackInternal, "external", fallbackExternal)
			return fallbackInternal, fallbackExternal
		}
		logger.Info("âœ… AListç™»å½•æˆåŠŸ")
	}
	
	// è·å–æ–‡ä»¶è¯¦ç»†ä¿¡æ¯ï¼ˆåŒ…å«raw_urlï¼‰
	fileInfo, err := s.alistClient.GetFileInfo(filePath)
	if err != nil {
		logger.Warn("âŒ è·å–æ–‡ä»¶ä¿¡æ¯å¤±è´¥ï¼Œä½¿ç”¨å›é€€URL", "path", filePath, "error", err)
		fallbackInternal := s.generateInternalURL(filePath)
		fallbackExternal := s.generateExternalURL(filePath)
		logger.Info("ğŸ”„ ä½¿ç”¨å›é€€URL", "internal", fallbackInternal, "external", fallbackExternal)
		return fallbackInternal, fallbackExternal
	}
	
	// ä½¿ç”¨æ—§å®ç°çš„ç®€å•é€»è¾‘ï¼šç›´æ¥è·å–raw_urlå¹¶åšåŸŸåæ›¿æ¢
	originalURL := fileInfo.Data.RawURL
	logger.Info("ğŸ¯ è·å–åˆ°åŸå§‹raw_url", "raw_url", originalURL)
	
	// å¦‚æœraw_urlä¸ºç©ºï¼Œä½¿ç”¨å›é€€é€»è¾‘
	if originalURL == "" {
		logger.Error("âŒ raw_urlä¸ºç©ºï¼Œè¿™ä¸åº”è¯¥å‘ç”Ÿï¼", "path", filePath, "fileInfo", fileInfo.Data)
		fallbackInternal := s.generateInternalURL(filePath)
		fallbackExternal := s.generateExternalURL(filePath)
		logger.Error("ğŸ”„ ä½¿ç”¨å›é€€URL", "internal", fallbackInternal, "external", fallbackExternal)
		return fallbackInternal, fallbackExternal
	}
	
	// é‡‡ç”¨æ—§å®ç°çš„ç®€å•æ›¿æ¢é€»è¾‘ï¼šåªåœ¨åŒ…å«fcalist-publicæ—¶æ›¿æ¢
	internalURL = originalURL
	externalURL = originalURL
	
	if strings.Contains(originalURL, "fcalist-public") {
		internalURL = strings.ReplaceAll(originalURL, "fcalist-public", "fcalist-internal")
		logger.Info("ğŸ”„ URLæ›¿æ¢å®Œæˆï¼ˆé‡‡ç”¨æ—§å®ç°é€»è¾‘ï¼‰", 
			"original", externalURL,
			"internal", internalURL,
			"replacement", "fcalist-public -> fcalist-internal")
	} else {
		logger.Info("â„¹ï¸  æ— éœ€URLæ›¿æ¢", "internal", internalURL, "external", externalURL)
	}
	
	logger.Info("âœ… æˆåŠŸè·å–ä¸‹è½½URLï¼ˆé‡‡ç”¨æ—§å®ç°çš„ç®€å•é€»è¾‘ï¼‰", 
		"path", filePath,
		"internal_url", internalURL, 
		"external_url", externalURL,
		"url_replaced", strings.Contains(originalURL, "fcalist-public"))
	
	return internalURL, externalURL
}

// generateInternalURL ç”Ÿæˆå†…éƒ¨ä¸‹è½½URLï¼ˆå›é€€æ–¹æ³•ï¼‰
func (s *AppFileService) generateInternalURL(path string) string {
	url := fmt.Sprintf("%s/d%s", s.config.Alist.BaseURL, path)
	logger.Info("ğŸ”„ ç”Ÿæˆå›é€€ä¸‹è½½URL", "url", url, "path", path)
	return url
}

// generateExternalURL ç”Ÿæˆå¤–éƒ¨è®¿é—®URLï¼ˆå›é€€æ–¹æ³•ï¼‰
func (s *AppFileService) generateExternalURL(path string) string {
	url := fmt.Sprintf("%s/p%s", s.config.Alist.BaseURL, path)
	logger.Info("ğŸ”„ ç”Ÿæˆå›é€€å¤–éƒ¨URL", "url", url, "path", path)
	return url
}

// getParentPath è·å–çˆ¶è·¯å¾„
func (s *AppFileService) getParentPath(path string) string {
	if path == "/" || path == "" {
		return ""
	}
	return utils.GetParentPath(path)
}

// GetCategoryFromPath ä»è·¯å¾„ä¸­åˆ†ææ–‡ä»¶ç±»å‹ï¼ˆä¼˜å…ˆçº§é«˜äºæ–‡ä»¶ååˆ†æï¼‰
func (s *AppFileService) GetCategoryFromPath(path string) string {
	if path == "" {
		return ""
	}

	// å°†è·¯å¾„è½¬ä¸ºå°å†™ä»¥ä¾¿åŒ¹é…
	pathLower := strings.ToLower(path)
	
	// æ£€æŸ¥ TVs å’Œ Movies çš„ä½ç½®ï¼Œé€‰æ‹©æœ€æ—©å‡ºç°çš„
	tvsIndex := strings.Index(pathLower, "tvs")
	moviesIndex := strings.Index(pathLower, "movies")
	
	// å¦‚æœä¸¤ä¸ªéƒ½å­˜åœ¨ï¼Œé€‰æ‹©æœ€æ—©å‡ºç°çš„ï¼ˆè·¯å¾„å±‚çº§æ›´é«˜çš„ï¼‰
	if tvsIndex != -1 && moviesIndex != -1 {
		if tvsIndex < moviesIndex {
			logger.Info("ğŸ” è·¯å¾„åŒæ—¶åŒ…å« tvs å’Œ moviesï¼Œé€‰æ‹©æ›´æ—©å‡ºç°çš„ tvs", "path", path, "tvsIndex", tvsIndex, "moviesIndex", moviesIndex)
			return "tv"
		} else {
			logger.Info("ğŸ” è·¯å¾„åŒæ—¶åŒ…å« tvs å’Œ moviesï¼Œé€‰æ‹©æ›´æ—©å‡ºç°çš„ movies", "path", path, "tvsIndex", tvsIndex, "moviesIndex", moviesIndex)
			return "movie"
		}
	}
	
	// ç®€åŒ–çš„ TVs åˆ¤æ–­ï¼šåªè¦è·¯å¾„åŒ…å« tvs å°±åˆ¤æ–­ä¸º tv
	if tvsIndex != -1 {
		return "tv"
	}

	// ç®€åŒ–çš„ Movies åˆ¤æ–­ï¼šåªè¦è·¯å¾„åŒ…å« movies å°±åˆ¤æ–­ä¸º movie  
	if moviesIndex != -1 {
		return "movie"
	}

	// ç»¼è‰ºç±»å‹æŒ‡ç¤ºå™¨
	varietyPathKeywords := []string{"/variety/", "/show/", "/ç»¼è‰º/", "/å¨±ä¹/"}
	for _, keyword := range varietyPathKeywords {
		if strings.Contains(pathLower, keyword) {
			return "variety"
		}
	}

	// ä¸€èˆ¬è§†é¢‘ç±»å‹æŒ‡ç¤ºå™¨
	videoPathKeywords := []string{"/videos/", "/video/", "/è§†é¢‘/"}
	for _, keyword := range videoPathKeywords {
		if strings.Contains(pathLower, keyword) {
			return "video"
		}
	}

	// å¦‚æœè·¯å¾„ä¸­æ²¡æœ‰æ˜ç¡®çš„ç±»å‹æŒ‡ç¤ºå™¨ï¼Œè¿”å›ç©ºå­—ç¬¦ä¸²
	return ""
}

// updateMediaStats æ›´æ–°åª’ä½“ç»Ÿè®¡
func (s *AppFileService) updateMediaStats(summary *contracts.FileSummary, filePath, filename string) {
	if !s.IsVideoFile(filename) {
		summary.OtherFiles++
		return
	}

	summary.VideoFiles++
	
	// ä½¿ç”¨ GetMediaType æ–¹æ³•ï¼Œå®ƒä¼šä¼˜å…ˆä½¿ç”¨è·¯å¾„åˆ†ç±»ï¼Œç„¶åå›é€€åˆ°æ–‡ä»¶ååˆ†ç±»
	mediaType := s.GetMediaType(filePath)
	logger.Info("ğŸ“Š æ–‡ä»¶ç»Ÿè®¡åˆ†ç±»", "filePath", filePath, "filename", filename, "mediaType", mediaType)
	
	switch mediaType {
	case "movie":
		summary.MovieFiles++
	case "tv":
		summary.TVFiles++
	default:
		summary.OtherFiles++
	}
}

// sortFiles æ–‡ä»¶æ’åº
func (s *AppFileService) sortFiles(files []contracts.FileResponse, sortBy, sortOrder string) {
	if sortBy == "" {
		sortBy = "name"
	}
	if sortOrder == "" {
		sortOrder = "asc"
	}

	sort.Slice(files, func(i, j int) bool {
		var result bool
		switch sortBy {
		case "size":
			result = files[i].Size < files[j].Size
		case "modified":
			result = files[i].Modified.Before(files[j].Modified)
		default: // name
			result = strings.ToLower(files[i].Name) < strings.ToLower(files[j].Name)
		}

		if sortOrder == "desc" {
			result = !result
		}

		return result
	})
}

// calculateFileSummary è®¡ç®—æ–‡ä»¶æ‘˜è¦
func (s *AppFileService) calculateFileSummary(files []contracts.FileResponse) contracts.FileSummary {
	summary := contracts.FileSummary{}

	for _, file := range files {
		summary.TotalFiles++
		summary.TotalSize += file.Size
		// ä¼ å…¥å®Œæ•´è·¯å¾„ç”¨äºè·¯å¾„åˆ†ç±»
		s.updateMediaStats(&summary, file.Path, file.Name)
	}

	summary.TotalSizeFormatted = s.FormatFileSize(summary.TotalSize)
	return summary
}

// generateSmartTVPath æ™ºèƒ½ç”Ÿæˆç”µè§†å‰§è·¯å¾„ï¼Œå°†å­£åº¦ä¿¡æ¯è§„èŒƒåŒ–
func (s *AppFileService) generateSmartTVPath(filePath, baseDir string) string {
	logger.Info("ğŸ¬ å¼€å§‹æ™ºèƒ½ç”µè§†å‰§è·¯å¾„è§£æ", "filePath", filePath)
	
	// ä»è·¯å¾„ä¸­æå–tvsä¹‹åçš„éƒ¨åˆ†
	pathLower := strings.ToLower(filePath)
	tvsIndex := strings.Index(pathLower, "tvs")
	if tvsIndex == -1 {
		logger.Warn("âš ï¸  è·¯å¾„ä¸­æœªæ‰¾åˆ°tvså…³é”®è¯", "filePath", filePath)
		return ""
	}
	
	// æå–tvsä¹‹åçš„è·¯å¾„éƒ¨åˆ†
	afterTvs := filePath[tvsIndex+3:] // è·³è¿‡"tvs"
	if strings.HasPrefix(afterTvs, "/") {
		afterTvs = afterTvs[1:] // å»æ‰å¼€å¤´çš„/
	}
	
	// åˆ†å‰²è·¯å¾„ä¸ºå„ä¸ªéƒ¨åˆ†
	pathParts := strings.Split(afterTvs, "/")
	if len(pathParts) < 2 {
		logger.Warn("âš ï¸  ç”µè§†å‰§è·¯å¾„ç»“æ„ä¸å®Œæ•´", "afterTvs", afterTvs, "parts", pathParts)
		return ""
	}
	
	logger.Info("ğŸ” è·¯å¾„ç»„ä»¶åˆ†æ", "pathParts", pathParts)
	
	// å¯»æ‰¾åŒ…å«å­£åº¦ä¿¡æ¯çš„ç›®å½•ï¼ˆä»æœ€æ·±å±‚å¼€å§‹æ£€æŸ¥ï¼‰
	var smartPath string
	lastIndex := len(pathParts) - 1
	
	// å¦‚æœæœ€åä¸€ä¸ªéƒ¨åˆ†æ˜¯æ–‡ä»¶ï¼ˆåŒ…å«æ–‡ä»¶æ‰©å±•åï¼‰ï¼Œåˆ™æ’é™¤å®ƒ
	if strings.Contains(pathParts[lastIndex], ".") {
		lastIndex-- 
	}
	
	for i := lastIndex; i >= 0; i-- {
		currentDir := pathParts[i]
		logger.Info("ğŸ” æ£€æŸ¥ç›®å½•", "index", i, "dir", currentDir)
		
		// å…ˆæ£€æŸ¥æ˜¯å¦åŒ…å«å®Œæ•´çš„èŠ‚ç›®åä¿¡æ¯
		extractedShowName := s.extractFullShowName(currentDir)
		if extractedShowName != "" {
			// æ£€æŸ¥æ˜¯å¦æ˜¯"å®è—è¡Œ"æˆ–å…¶ä»–ç‰¹æ®Šç³»åˆ—ï¼ˆåŒ…å«æ›´å¤šä¿¡æ¯ï¼‰
			if strings.Contains(extractedShowName, "å®è—è¡Œ") || strings.Contains(extractedShowName, "å…¬ç›Šå­£") {
				// å¯¹äºç‰¹æ®Šç³»åˆ—ï¼Œç›´æ¥ä½¿ç”¨å®Œæ•´èŠ‚ç›®å
				smartPath = utils.JoinPath(baseDir, "tvs", extractedShowName)
				logger.Info("âœ… ä½¿ç”¨å®Œæ•´ç‰¹æ®ŠèŠ‚ç›®å", 
					"åŸè·¯å¾„", filePath,
					"å®Œæ•´èŠ‚ç›®å", extractedShowName,
					"æ™ºèƒ½è·¯å¾„", smartPath)
				return smartPath
			}
		}
		
		// å°è¯•ä»å½“å‰ç›®å½•æå–å­£åº¦ä¿¡æ¯å¹¶ç”Ÿæˆè§„èŒƒåŒ–è·¯å¾„
		seasonNumber := s.extractSeasonNumber(currentDir)
		if seasonNumber > 0 {
			// ä½¿ç”¨ç¬¬ä¸€å±‚ç›®å½•ä½œä¸ºåŸºç¡€èŠ‚ç›®åï¼Œç”Ÿæˆ èŠ‚ç›®å/S##
			baseShowName := pathParts[0]
			seasonCode := fmt.Sprintf("S%02d", seasonNumber)
			smartPath = utils.JoinPath(baseDir, "tvs", baseShowName, seasonCode)
			
			logger.Info("âœ… ä»ç›®å½•ç”Ÿæˆå­£åº¦è·¯å¾„", 
				"åŸè·¯å¾„", filePath,
				"åŸºç¡€èŠ‚ç›®å", baseShowName,
				"å­£åº¦ç›®å½•", currentDir,
				"å­£åº¦", seasonNumber,
				"å­£åº¦ä»£ç ", seasonCode,
				"æ™ºèƒ½è·¯å¾„", smartPath)
			
			return smartPath
		}
		
		// æœ€åæ£€æŸ¥å…¶ä»–å®Œæ•´èŠ‚ç›®å
		if extractedShowName != "" {
			// ç›´æ¥ä½¿ç”¨æå–çš„å®Œæ•´èŠ‚ç›®åä½œä¸ºæœ€ç»ˆç›®å½•
			smartPath = utils.JoinPath(baseDir, "tvs", extractedShowName)
			
			logger.Info("âœ… ä½¿ç”¨å®Œæ•´èŠ‚ç›®åç”Ÿæˆè·¯å¾„", 
				"åŸè·¯å¾„", filePath,
				"ç›®æ ‡ç›®å½•", currentDir,
				"æå–èŠ‚ç›®å", extractedShowName,
				"æ™ºèƒ½è·¯å¾„", smartPath)
			
			return smartPath
		}
	}
	
	// å¦‚æœä¸Šè¿°æ–¹æ³•å¤±è´¥ï¼Œå°è¯•ä¼ ç»Ÿçš„å­£åº¦è§£ææ–¹æ³•
	showName := pathParts[0]
	seasonDir := pathParts[1]
	
	logger.Info("ğŸ”„ å›é€€åˆ°ä¼ ç»Ÿè§£æ", "showName", showName, "seasonDir", seasonDir)
	
	// è§£æå­£åº¦ä¿¡æ¯
	seasonNumber := s.extractSeasonNumber(seasonDir)
	if seasonNumber > 0 {
		// æ„å»ºè§„èŒƒåŒ–è·¯å¾„ï¼š/downloads/tvs/èŠ‚ç›®å/S##
		seasonCode := fmt.Sprintf("S%02d", seasonNumber)
		smartPath = utils.JoinPath(baseDir, "tvs", showName, seasonCode)
		
		logger.Info("âœ… ä¼ ç»Ÿæ–¹æ³•ç”Ÿæˆè·¯å¾„", 
			"åŸè·¯å¾„", filePath,
			"èŠ‚ç›®å", showName, 
			"å­£åº¦", seasonNumber,
			"å­£åº¦ä»£ç ", seasonCode,
			"æ™ºèƒ½è·¯å¾„", smartPath)
		
		return smartPath
	}
	
	logger.Info("âš ï¸  æœªèƒ½è§£æå­£åº¦ä¿¡æ¯ï¼Œä½¿ç”¨åŸå§‹é€»è¾‘", "seasonDir", seasonDir)
	return ""
}

// extractSeasonNumber ä»ç›®å½•åä¸­æå–å­£åº¦ç¼–å·
func (s *AppFileService) extractSeasonNumber(dirName string) int {
	if dirName == "" {
		return 0
	}
	
	dirLower := strings.ToLower(dirName)
	
	// åŒ¹é…å„ç§å­£åº¦æ ¼å¼
	patterns := []struct {
		pattern string
		extract func(string) int
	}{
		// ç¬¬Xå­£ æ ¼å¼
		{"ç¬¬", func(s string) int {
			if idx := strings.Index(s, "ç¬¬"); idx != -1 {
				after := s[idx+len("ç¬¬"):]
				if seasonIdx := strings.Index(after, "å­£"); seasonIdx != -1 {
					seasonStr := after[:seasonIdx]
					// è½¬æ¢ä¸­æ–‡æ•°å­—æˆ–é˜¿æ‹‰ä¼¯æ•°å­—
					return chineseOrArabicToNumber(seasonStr)
				}
			}
			return 0
		}},
		// Season X æ ¼å¼
		{"season", func(s string) int {
			if idx := strings.Index(s, "season"); idx != -1 {
				after := strings.TrimSpace(s[idx+6:])
				// æå–æ•°å­—éƒ¨åˆ†
				var numStr string
				for _, char := range after {
					if char >= '0' && char <= '9' {
						numStr += string(char)
					} else {
						break
					}
				}
				if num, err := strconv.Atoi(numStr); err == nil && num > 0 {
					return num
				}
			}
			return 0
		}},
		// SXX æ ¼å¼
		{"s", func(s string) int {
			if len(s) >= 2 && s[0] == 's' {
				numStr := ""
				for i := 1; i < len(s) && i < 4; i++ { // æœ€å¤šå–3ä½æ•°å­—
					if s[i] >= '0' && s[i] <= '9' {
						numStr += string(s[i])
					} else {
						break
					}
				}
				if num, err := strconv.Atoi(numStr); err == nil && num > 0 {
					return num
				}
			}
			return 0
		}},
		// ç›´æ¥åŒ…å«å¹´ä»½+å­£åº¦ä¿¡æ¯ï¼Œå¦‚"æé™æŒ‘æˆ˜ç¬¬9å­£2023"
		{"", func(s string) int {
			// æŸ¥æ‰¾"ç¬¬Xå­£"æ¨¡å¼
			for i := 0; i < len(s)-1; i++ {
				if s[i:i+1] == "ç¬¬" && i+2 < len(s) && s[i+2:i+3] == "å­£" {
					seasonChar := s[i+1 : i+2]
					return chineseOrArabicToNumber(seasonChar)
				}
			}
			return 0
		}},
	}
	
	// å°è¯•å„ç§æ¨¡å¼
	for _, pattern := range patterns {
		if pattern.pattern == "" || strings.Contains(dirLower, pattern.pattern) {
			if num := pattern.extract(dirLower); num > 0 {
				logger.Info("ğŸ¯ æˆåŠŸæå–å­£åº¦ç¼–å·", "dirName", dirName, "pattern", pattern.pattern, "seasonNumber", num)
				return num
			}
		}
	}
	
	logger.Info("âš ï¸  æ— æ³•ä»ç›®å½•åæå–å­£åº¦ç¼–å·", "dirName", dirName)
	return 0
}

// extractFullShowName æå–å®Œæ•´çš„èŠ‚ç›®åï¼ˆåŒ…å«å­£åº¦ä¿¡æ¯ï¼‰
func (s *AppFileService) extractFullShowName(dirName string) string {
	if dirName == "" {
		return ""
	}
	
	logger.Info("ğŸ” åˆ†æèŠ‚ç›®å", "dirName", dirName)
	
	// æ£€æŸ¥æ˜¯å¦åŒ…å«å­£åº¦å…³é”®è¯ï¼Œå¦‚æœåŒ…å«åˆ™è®¤ä¸ºè¿™æ˜¯å®Œæ•´çš„èŠ‚ç›®å
	seasonKeywords := []string{"ç¬¬", "å­£", "season", "å®è—è¡Œ", "å…¬ç›Šå­£"}
	hasSeasonInfo := false
	
	dirLower := strings.ToLower(dirName)
	for _, keyword := range seasonKeywords {
		if strings.Contains(dirLower, strings.ToLower(keyword)) {
			hasSeasonInfo = true
			logger.Info("ğŸ¯ å‘ç°å­£åº¦å…³é”®è¯", "dirName", dirName, "keyword", keyword)
			break
		}
	}
	
	if hasSeasonInfo {
		// æ¸…ç†ç›®å½•åï¼Œç§»é™¤ä¸å¿…è¦çš„åç¼€ä¿¡æ¯
		cleanName := s.cleanShowName(dirName)
		if cleanName != "" {
			logger.Info("âœ… æå–å®Œæ•´èŠ‚ç›®å", "åŸç›®å½•å", dirName, "æ¸…ç†å", cleanName)
			return cleanName
		}
	}
	
	logger.Info("âš ï¸  ç›®å½•ä¸åŒ…å«å­£åº¦ä¿¡æ¯", "dirName", dirName)
	return ""
}

// cleanShowName æ¸…ç†èŠ‚ç›®åï¼Œç§»é™¤ä¸å¿…è¦çš„åç¼€ä¿¡æ¯
func (s *AppFileService) cleanShowName(showName string) string {
	if showName == "" {
		return ""
	}
	
	// ç§»é™¤å¸¸è§çš„åç¼€ä¿¡æ¯
	suffixesToRemove := []string{
		"ï¼ˆ", "(", // ç§»é™¤æ‹¬å·åŠä¹‹åçš„å†…å®¹
		"2021", "2022", "2023", "2024", "2025", // ç§»é™¤å¹´ä»½
		"å…¨", "æœŸå…¨", "å®Œç»“", "[", "ã€", // ç§»é™¤å®Œç»“æ ‡è®°
	}
	
	cleaned := showName
	for _, suffix := range suffixesToRemove {
		if idx := strings.Index(cleaned, suffix); idx != -1 {
			cleaned = cleaned[:idx]
			logger.Info("ğŸ§¹ ç§»é™¤åç¼€", "åŸå", showName, "åç¼€", suffix, "æ¸…ç†å", cleaned)
		}
	}
	
	// å»é™¤å‰åç©ºç™½
	cleaned = strings.TrimSpace(cleaned)
	
	// å¦‚æœæ¸…ç†åä¸ºç©ºæˆ–å¤ªçŸ­ï¼Œè¿”å›åŸå
	if len(cleaned) < 3 {
		logger.Info("âš ï¸  æ¸…ç†ååç§°å¤ªçŸ­ï¼Œä½¿ç”¨åŸå", "cleaned", cleaned, "original", showName)
		return showName
	}
	
	logger.Info("âœ… èŠ‚ç›®åæ¸…ç†å®Œæˆ", "åŸå", showName, "æ¸…ç†å", cleaned)
	return cleaned
}

// chineseOrArabicToNumber è½¬æ¢ä¸­æ–‡æ•°å­—æˆ–é˜¿æ‹‰ä¼¯æ•°å­—ä¸ºæ•´æ•°
func chineseOrArabicToNumber(str string) int {
	if str == "" {
		return 0
	}
	
	// å…ˆå°è¯•ç›´æ¥è½¬æ¢é˜¿æ‹‰ä¼¯æ•°å­—
	if num, err := strconv.Atoi(str); err == nil {
		return num
	}
	
	// è½¬æ¢ä¸­æ–‡æ•°å­—
	chineseNumbers := map[string]int{
		"ä¸€": 1, "äºŒ": 2, "ä¸‰": 3, "å››": 4, "äº”": 5,
		"å…­": 6, "ä¸ƒ": 7, "å…«": 8, "ä¹": 9, "å": 10,
		"1": 1, "2": 2, "3": 3, "4": 4, "5": 5,
		"6": 6, "7": 7, "8": 8, "9": 9,
	}
	
	if num, exists := chineseNumbers[str]; exists {
		return num
	}
	
	return 0
}